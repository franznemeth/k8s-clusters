---
## Container runtime
## docker for docker, crio for cri-o and containerd for containerd.
## Additionally you can set this to kubeadm if you want to install etcd using kubeadm
## Kubeadm etcd deployment is experimental and only available for new deployments
## If this is not set, container manager will be inherited from the Kubespray defaults
## and not from k8s_cluster/k8s-cluster.yml, which might not be what you want.
## Also this makes possible to use different container manager for etcd nodes.
container_manager: containerd

## Settings for etcd deployment type
# Set this to docker if you are using container_manager: docker
etcd_deployment_type: kubeadm

etcd_quota_backend_bytes: "8589934592"

# Cilium helm installation
kube_network_plugin: custom_cni
# This must be set to root otherwise cilium agent init fails with permission denied while copying to /opt/cni/bin
cni_bin_owner: root
custom_cni_chart_namespace: kube-system
custom_cni_chart_release_name: cilium
custom_cni_chart_repository_name: cilium
custom_cni_chart_repository_url: https://helm.cilium.io
custom_cni_chart_ref: cilium/cilium
custom_cni_chart_version: 1.15.2
custom_cni_chart_values:
  # -- Roll out cilium agent pods automatically when configmap is updated.
  rollOutCiliumPods: true

  # -- Annotate k8s node upon initialization with Cilium's metadata.
  annotateK8sNode: true
  dnsPolicy: "ClusterFirstWithHostNet"
  bandwidthManager:
    # -- Enable bandwidth manager infrastructure (also prerequirement for BBR)
    enabled: true
    # -- Activate BBR TCP congestion control for Pods
    bbr: false

  # -- Configure L2 announcements
  l2announcements:
    # -- Enable L2 announcements
    enabled: true

  # -- Configure L2 pod announcements
  l2podAnnouncements:
    # -- Enable L2 pod announcements
    enabled: false
    # -- Interface used for sending Gratuitous ARP pod announcements
    interface: "eth0"

  externalIPs:
    # -- Enable ExternalIPs service support.
    enabled: true

  cni:
    # -- Install the CNI configuration and binary files into the filesystem.
    install: true

  ingressController:
    # -- Enable cilium ingress controller
    # This will automatically set enable-envoy-config as well.
    enabled: false

    # -- Default ingress load balancer mode
    # Supported values: shared, dedicated
    # For granular control, use the following annotations on the ingress resource
    # ingress.cilium.io/loadbalancer-mode: shared|dedicated,
    loadbalancerMode: dedicated

    # -- Load-balancer service in shared mode.
    # This is a single load-balancer service for all Ingress resources.
    service:
      # -- Service name
      name: cilium-ingress
      # -- Labels to be added for the shared LB service
      labels: {}
      # -- Annotations to be added for the shared LB service
      annotations: {}
      # -- Service type for the shared LB service
      type: LoadBalancer
      # -- Configure a specific nodePort for insecure HTTP traffic on the shared LB service
      insecureNodePort: ~
      # -- Configure a specific nodePort for secure HTTPS traffic on the shared LB service
      secureNodePort: ~

  gatewayAPI:
    # -- Enable support for Gateway API in cilium
    # This will automatically set enable-envoy-config as well.
    enabled: false

    # -- SecretsNamespace is the namespace in which envoy SDS will retrieve TLS secrets from.
    secretsNamespace:
      # -- Create secrets namespace for Gateway API.
      create: true

      # -- Name of Gateway API secret namespace.
      name: cilium-secrets

      # -- Enable secret sync, which will make sure all TLS secrets used by Ingress are synced to secretsNamespace.name.
      # If disabled, TLS secrets must be maintained externally.
      sync: true

  hubble:
    enabled: true
    relay:
      enabled: true
    ui:
      enabled: true
      ingress:
        enabled: true
        annotations:
          cert-manager.io/cluster-issuer: dns-int
        className: "internal"
        hosts:
          - cilium.int.fnemeth.net
        tls:
          - secretName: cilium-tls
            hosts:
              - cilium.int.fnemeth.net

  # -- Configure the kube-proxy replacement in Cilium BPF datapath
  # Valid options are "true", "false", "disabled" (deprecated), "partial" (deprecated), "strict" (deprecated).
  # ref: https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/
  kubeProxyReplacement: "true"

  # -- Enables egress gateway to redirect and SNAT the traffic that leaves the
  # cluster.
  egressGateway:
    enabled: false
    # -- Install egress gateway IP rules and routes in order to properly steer
    # egress gateway traffic to the correct ENI interface
    installRoutes: false

  operator:
    replicas: 1
    nodeSelector:
      kubernetes.io/os: linux
      node-role.kubernetes.io/control-plane: ""
  k8sServiceHost: "10.11.12.171"
  k8sServicePort: "6443"
  nodeinit:
    enabled: true
  ipam:
    mode: "kubernetes"
    operator:
      clusterPoolIPv4PodCIDRList: ["{{ kube_pods_subnet }}"]

# Remove kube-proxy to be replaced by cilium
kube_proxy_remove: true

## NTP Settings
# Start the ntpd or chrony service and enable it at system boot.
ntp_enabled: true
ntp_manage_config: true
ntp_servers:
  - "0.pool.ntp.org iburst"
  - "1.pool.ntp.org iburst"
  - "2.pool.ntp.org iburst"
  - "3.pool.ntp.org iburst"

## Used to control no_log attribute
unsafe_show_logs: true

# Metrics Server deployment
metrics_server_enabled: true

kube_version: v1.29.2

# Random shifts for retrying failed ops like pushing/downloading
retry_stagger: 5

# Cluster Loglevel configuration
kube_log_level: 2

# Kubernetes internal network for services, unused block of space.
kube_service_addresses: 10.43.0.0/16
kube_pods_subnet: 10.42.0.0/16

#kube_api_anonymous_auth: false
authorization_modes: ['Node', 'RBAC']
kube_apiserver_request_timeout: 120s
kube_apiserver_service_account_lookup: true
kube_apiserver_enable_admission_plugins:
  - EventRateLimit
  - AlwaysPullImages
  - ServiceAccount
  - NamespaceLifecycle
  - NodeRestriction
  - LimitRanger
  - ResourceQuota
  - MutatingAdmissionWebhook
  - ValidatingAdmissionWebhook
  - PodNodeSelector
kube_apiserver_admission_control_config_file: true
kube_apiserver_admission_event_rate_limits:
  limit_1:
    type: Namespace
    qps: 150
    burst: 300
    cache_size: 2000
  limit_2:
    type: User
    qps: 150
    burst: 300
kube_profiling: false
kubelet_authorization_mode_webhook: true
kubelet_authentication_token_webhook: true
kube_read_only_port: 0
kubelet_rotate_server_certificates: true
kubelet_protect_kernel_defaults: true
#kubelet_event_record_qps: 1
#kubelet_event_record_qps: 50
kubelet_rotate_certificates: true
kubelet_streaming_connection_idle_timeout: "5m"
kubelet_make_iptables_util_chains: true
kubelet_feature_gates: ["RotateKubeletServerCertificate=true", "ValidatingAdmissionPolicy=true"]
kubelet_seccomp_default: true

## Encrypting Secret Data at Rest
kube_encrypt_secret_data: true
kube_encryption_resources: [secrets]
kube_encryption_algorithm: "secretbox"

# DNS configuration.
# Subdomains of DNS domain to be resolved via /etc/resolv.conf for hostnet pods
ndots: 1

# audit log for kubernetes
kubernetes_audit: false

# Make a copy of kubeconfig on the host that runs Ansible in {{ inventory_dir }}/artifacts
kubeconfig_localhost: true

## Support tls min version, Possible values: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.
tls_min_version: "VersionTLS13"

## Support tls cipher suites.
tls_cipher_suites:
  - TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384
  - TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384
  - TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256
  - TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256
  - TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256

## Amount of time to retain events. (default 1h0m0s)
event_ttl_duration: "4h0m0s"

## Automatically renew K8S control plane certificates on first Monday of each month
auto_renew_certificates: true
# First Monday of each month
auto_renew_certificates_systemd_calendar: "Mon *-*-1,2,3,4,5,6,7 03:{{ groups['kube_control_plane'].index(inventory_hostname) }}0:00"
